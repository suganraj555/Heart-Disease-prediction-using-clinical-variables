{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLLvEM7-tmQJ",
        "outputId": "f132b1ce-b281-4b21-9e1c-6184d2b31371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=8d603e52a3e2fe77a566b2b1fcdb8ba72490a0e8c62dd2a2fbc22834e58a342d\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "EzSkKx4fujMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp=SparkSession.builder.appName('heart_disease').getOrCreate()\n",
        "path='/content/Heart_Disease_Prediction.csv'\n",
        "df=sp.read.format('csv').options(inferSchema=True,header=True).load(path)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4F3qJufuTy-",
        "outputId": "12da3e12-9ef6-47ef-b364-44a3b0eb9946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+---+---------------+---+-----------+------------+-----------+------+---------------+-------------+-----------+-----------------------+--------+-------------+\n",
            "|index|Age|Sex|Chest pain type| BP|Cholesterol|FBS over 120|EKG results|Max HR|Exercise angina|ST depression|Slope of ST|Number of vessels fluro|Thallium|Heart Disease|\n",
            "+-----+---+---+---------------+---+-----------+------------+-----------+------+---------------+-------------+-----------+-----------------------+--------+-------------+\n",
            "|    0| 70|  1|              4|130|        322|           0|          2|   109|              0|          2.4|          2|                      3|       3|     Presence|\n",
            "|    1| 67|  0|              3|115|        564|           0|          2|   160|              0|          1.6|          2|                      0|       7|      Absence|\n",
            "|    2| 57|  1|              2|124|        261|           0|          0|   141|              0|          0.3|          1|                      0|       7|     Presence|\n",
            "|    3| 64|  1|              4|128|        263|           0|          0|   105|              1|          0.2|          2|                      1|       7|      Absence|\n",
            "|    4| 74|  0|              2|120|        269|           0|          2|   121|              1|          0.2|          1|                      1|       3|      Absence|\n",
            "|    5| 65|  1|              4|120|        177|           0|          0|   140|              0|          0.4|          1|                      0|       7|      Absence|\n",
            "|    6| 56|  1|              3|130|        256|           1|          2|   142|              1|          0.6|          2|                      1|       6|     Presence|\n",
            "|    7| 59|  1|              4|110|        239|           0|          2|   142|              1|          1.2|          2|                      1|       7|     Presence|\n",
            "|    8| 60|  1|              4|140|        293|           0|          2|   170|              0|          1.2|          2|                      2|       7|     Presence|\n",
            "|    9| 63|  0|              4|150|        407|           0|          2|   154|              0|          4.0|          2|                      3|       7|     Presence|\n",
            "|   10| 59|  1|              4|135|        234|           0|          0|   161|              0|          0.5|          2|                      0|       7|      Absence|\n",
            "|   11| 53|  1|              4|142|        226|           0|          2|   111|              1|          0.0|          1|                      0|       7|      Absence|\n",
            "|   12| 44|  1|              3|140|        235|           0|          2|   180|              0|          0.0|          1|                      0|       3|      Absence|\n",
            "|   13| 61|  1|              1|134|        234|           0|          0|   145|              0|          2.6|          2|                      2|       3|     Presence|\n",
            "|   14| 57|  0|              4|128|        303|           0|          2|   159|              0|          0.0|          1|                      1|       3|      Absence|\n",
            "|   15| 71|  0|              4|112|        149|           0|          0|   125|              0|          1.6|          2|                      0|       3|      Absence|\n",
            "|   16| 46|  1|              4|140|        311|           0|          0|   120|              1|          1.8|          2|                      2|       7|     Presence|\n",
            "|   17| 53|  1|              4|140|        203|           1|          2|   155|              1|          3.1|          3|                      0|       7|     Presence|\n",
            "|   18| 64|  1|              1|110|        211|           0|          2|   144|              1|          1.8|          2|                      0|       3|      Absence|\n",
            "|   19| 40|  1|              1|140|        199|           0|          0|   178|              1|          1.4|          1|                      0|       7|      Absence|\n",
            "+-----+---+---+---------------+---+-----------+------------+-----------+------+---------------+-------------+-----------+-----------------------+--------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "spark = SparkSession.builder.appName(\"DecisionTree\").getOrCreate()\n",
        "\n",
        "df=spark.read.csv(\"/content/Heart_Disease_Prediction.csv\",header=True)\n",
        "\n",
        "\n",
        "numeric_columns = [\"Age\", \"Chest pain type\", \"BP\", \"Cholesterol\"]\n",
        "for column in numeric_columns:\n",
        "    df = df.withColumn(column, df[column].cast(\"double\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "8txYpDxxuvKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns = [\"Age\", \"Chest pain type\", \"BP\", \"Cholesterol\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "\n",
        "label_indexer = StringIndexer(inputCol=\"Heart Disease\", outputCol=\"label\")\n",
        "\n",
        "\n",
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[assembler, label_indexer, dt])\n",
        "\n",
        "\n",
        "(training_data, test_data) = df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "AhwkueQTwgrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(training_data)\n",
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"label\", \"prediction\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mif0IrafxlPU",
        "outputId": "11df349a-d717-468e-9f1a-e0eb7950888a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+\n",
            "|label|prediction|\n",
            "+-----+----------+\n",
            "|  0.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  0.0|       1.0|\n",
            "|  0.0|       0.0|\n",
            "+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE6D6w2rzhxo",
        "outputId": "028ee64a-2c60-4bea-a1e4-d6cd462ea611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 66.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "paramGrid = ParamGridBuilder()\\\n",
        "            .addGrid(dt.maxDepth, [3,5,7])\\\n",
        "            .addGrid(dt.minInstancesPerNode, [1,3,5])\\\n",
        "            .build()"
      ],
      "metadata": {
        "id": "_RGfKjBdzyc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid,\n",
        "                      evaluator=MulticlassClassificationEvaluator(\n",
        "                      labelCol='label', predictionCol='prediction', metricName='accuracy'),\n",
        "                      numFolds=5)\n",
        "\n",
        "cvModel = crossval.fit(training_data)\n",
        "\n",
        "best_model = cvModel.bestModel\n",
        "\n",
        "predictions = best_model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMf74Cuuz1OP",
        "outputId": "0c2278bf-b0fa-42c4-e328-6a2f58aa806d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "GXBa6Dd548aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier"
      ],
      "metadata": {
        "id": "RxkXdLKe5el6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = [\"Age\", \"Chest pain type\", \"BP\", \"Cholesterol\",\n",
        "                   \"FBS over 120\",\"EKG results\",\"Max HR\",\"Exercise angina\",\n",
        "                   \"ST depression\",\"Slope of ST\",\"Number of vessels fluro\",\"Thallium\"]\n",
        "for column in numeric_columns:\n",
        "    df = df.withColumn(column, df[column].cast(\"double\"))"
      ],
      "metadata": {
        "id": "Q0vSImXd6K1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns2 = [\"Age\", \"Chest pain type\", \"BP\", \"Cholesterol\",\n",
        "                   \"FBS over 120\",\"EKG results\",\"Max HR\",\"Exercise angina\",\n",
        "                   \"ST depression\",\"Slope of ST\",\"Number of vessels fluro\",\"Thallium\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns2, outputCol=\"features2\")\n",
        "\n",
        "\n",
        "label_indexer = StringIndexer(inputCol=\"Heart Disease\", outputCol=\"label2\")\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(featuresCol=\"features2\", labelCol=\"label2\")\n",
        "\n",
        "\n",
        "pipeline2 = Pipeline(stages=[assembler, label_indexer, rf])\n",
        "\n",
        "\n",
        "(training_data2, test_data2) = df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "akDpsg1p4_6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = pipeline2.fit(training_data2)\n",
        "predictions2 = model2.transform(test_data2)\n",
        "predictions2.select(\"label2\", \"prediction\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCKRsul-5Nh9",
        "outputId": "5a194ce7-b788-4fe5-8da2-c133c6196e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+\n",
            "|label2|prediction|\n",
            "+------+----------+\n",
            "|   0.0|       1.0|\n",
            "|   1.0|       1.0|\n",
            "|   1.0|       1.0|\n",
            "|   0.0|       1.0|\n",
            "|   0.0|       0.0|\n",
            "+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "param_grid2 = ParamGridBuilder() \\\n",
        "    .addGrid(rf.numTrees, [10, 20, 30]) \\\n",
        "    .addGrid(rf.maxDepth, [5, 10, 15])  \\\n",
        "    .addGrid(rf.minInstancesPerNode, [1, 5, 10]) \\\n",
        "    .build()"
      ],
      "metadata": {
        "id": "qXagFpLw6hPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossval2 = CrossValidator(estimator=pipeline2, estimatorParamMaps=paramGrid2,\n",
        "                      evaluator=MulticlassClassificationEvaluator(\n",
        "                      labelCol='label2', predictionCol='prediction', metricName='accuracy'),\n",
        "                      numFolds=5)\n",
        "\n",
        "cvModel2 = crossval2.fit(training_data2)\n",
        "\n",
        "best_model2 = cvModel2.bestModel\n",
        "\n",
        "predictions2 = best_model2.transform(test_data2)\n",
        "\n",
        "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"label2\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy2 = evaluator2.evaluate(predictions2)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy2:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQwPFqGJ6jky",
        "outputId": "5b5fa624-689f-4a24-fc22-d39d4a966180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.69\n"
          ]
        }
      ]
    }
  ]
}